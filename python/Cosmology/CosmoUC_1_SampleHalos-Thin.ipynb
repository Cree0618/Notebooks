{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define set of halos we want to investigate further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:<br/> Query for Halos: shows usage of CasJobs.<br/> Store them in HDF5 and CSV file : shows usage of MyScratch/File<br/> Store them in a table : shows usage of MyDB<br/> Share CSV file :  shows usage of SciDrive<br/> <!-- <img src=\"images/uc1.png\"/> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  cleanup MyDB, MyScratchDB (NOT halo_particles_all), OwnCloud/cosmodata/ (NOT HaloParticles_All.h5), SciDrive/cosmodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token=\"d68fcd6768b54c55ad1ec279a123421e\"\n",
    "import sys\n",
    "sys.argv.append(\"--ident=\"+token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries.\n",
    "# \"BOILERPLATE\"\n",
    "import SciServer.CasJobs\n",
    "import SciServer.Keystone\n",
    "import SciServer.SciDrive\n",
    "import os\n",
    "import pandas\n",
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executeQuery POST response:  200 OK\n",
      "Found 33 rows\n"
     ]
    }
   ],
   "source": [
    "# define SQL: query from Millennium halo merger trees tab \n",
    "# find halos with mass in given range\n",
    "query = \"\"\"SELECT haloId,np,x,y,z, halfMassRadius \n",
    "             FROM mpahalotrees..mr \n",
    "            WHERE snapnum=63 \n",
    "              AND np between 200000 AND 210000\"\"\"\n",
    "\n",
    "# query CasJobs table. Using MPAHaloTrees as context\n",
    "queryResponse = SciServer.CasJobs.executeQuery(query, \"MPAHaloTrees\")\n",
    "\n",
    "# parse results into py DataFrame for further in memory processing\n",
    "halosDF = pandas.read_csv(queryResponse,index_col=0)\n",
    "print(\"Found \"+str(halosDF.count()[0])+\" rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GOT  persistent/FileDB/cosmodata and make sure cosmdata is empty (apart from precooked file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store result as HDF5 file \n",
    "h5store = pandas.HDFStore('cosmodata/HaloSample.h5')\n",
    "h5store['halos']=halosDF\n",
    "h5store.close()\n",
    "\n",
    "# store result as CSV file\n",
    "halosDF.to_csv('cosmodata/HaloSample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GOTO persistent/FileDB/cosmodata and see data has appeared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GOTO CasJobs schema browser and ensure no table halo_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executeQuery POST response:  200 OK\n",
      "Uploading  2173 bytes...\n",
      "uploadCVSDataFrameToTable POST response:  200 OK\n"
     ]
    }
   ],
   "source": [
    "# when writing to MyDB, MUST have token\n",
    "token = SciServer.Session.getKeystoneToken()\n",
    "\n",
    "# create table in MyDB and write to it\n",
    "ddl = \"\"\"CREATE TABLE halo_sample(haloID bigint,np integer,x real,y real,z real, halfMassRadius real)\"\"\"\n",
    "response = SciServer.CasJobs.executeQuery(ddl,token=token)\n",
    "\n",
    "# upload directly form DataFrame\n",
    "response=SciServer.CasJobs.uploadPandasDataFrameToTable(halosDF,\"halo_sample\",token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GOTO CasJobs and see that table was written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make copy of CSV file in new container in SciDrive\n",
    "filename = 'cosmodata/HaloSample.csv'\n",
    "f = open(filename, 'rb')\n",
    "data1 = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GOTO SciDrive and show there is no container cosmodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make copy of CSV file in new container in SciDrive\n",
    "filename = 'cosmodata/HaloSample.csv'\n",
    "f = open(filename, 'rb')\n",
    "data1 = f.read()\n",
    "f.close()\n",
    "\n",
    "# create container\n",
    "container = 'cosmodata'\n",
    "SciServer.SciDrive.createContainer(container)\n",
    "\n",
    "# create file\n",
    "scidrivename_name = container+\"/HaloSample.csv\"\n",
    "SciServer.SciDrive.upload(scidrivename_name, data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GOTO SciDrive and see data was written"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
